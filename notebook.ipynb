{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b43acd43",
   "metadata": {},
   "source": [
    "An excercise, recreating the results reported in [this paper](https://academic.oup.com/bioinformatics/article/39/4/btad187/7114029) using [the codes proviced by the authors](https://github.com/biomed-AI/GraphBepi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975ab329",
   "metadata": {},
   "source": [
    "importing necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b008e8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/askari/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics as tm\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pad_sequence,pack_sequence,pack_padded_sequence,pad_packed_sequence\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from tqdm import tqdm,trange\n",
    "import esm\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import numpy as np\n",
    "import requests as rq\n",
    "import time\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import Callback,EarlyStopping,ModelCheckpoint\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157718d9",
   "metadata": {},
   "source": [
    "contents of tool.py, used to evaluate the perfomance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b82e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class METRICS:\n",
    "    def __init__(self,device='cpu'):\n",
    "        self.device=device\n",
    "        self.auroc=tm.AUROC(task='binary').to(device)\n",
    "        self.auprc=tm.AveragePrecision(task='binary').to(device)\n",
    "        self.roc=tm.ROC(task='binary').to(device)\n",
    "        self.prc=tm.PrecisionRecallCurve(task='binary').to(device)\n",
    "        self.rec=tm.Recall(task='binary').to(device)\n",
    "        self.prec=tm.Precision(task='binary').to(device)\n",
    "        self.f1=tm.F1Score(task='binary').to(device)\n",
    "        self.mcc=tm.MatthewsCorrCoef(task='binary').to(device)\n",
    "        f=lambda a,b,c,d,e:(a/(a+d)+c/(b+c))/2\n",
    "        self.stat=tm.StatScores(task='binary').to(device)\n",
    "        self.bacc=lambda x,y:f(*self.stat(x,y))\n",
    "\n",
    "    def to(self,pred,y):\n",
    "        return pred.to(self.device),y.to(self.device)\n",
    "    def calc_thresh(self,pred,y):\n",
    "        pred,y=self.to(pred,y)\n",
    "        prec, rec, thresholds = self.prc(pred,y)\n",
    "        f1=(2*prec*rec/(prec+rec)).nan_to_num(0)[:-1]\n",
    "        threshold = thresholds[torch.argmax(f1)]\n",
    "        return threshold\n",
    "    def calc_prc(self,pred,y):\n",
    "        pred,y=self.to(pred,y)\n",
    "        auroc = self.auroc(pred,y)\n",
    "        prec, rec, th1 = self.prc(pred,y)\n",
    "        auprc = self.auprc(pred,y)\n",
    "        fpr, tpr, th2 = self.roc(pred,y)\n",
    "        return {\n",
    "            'AUROC':auroc.cpu().item(),'AUPRC':auprc.cpu().item(),'prc':[rec[:-1],prec[:-1],th1],'roc':[fpr,tpr,th2]\n",
    "        }\n",
    "    def __call__(self,pred,y,threshold=None):\n",
    "        pred,y=self.to(pred,y)\n",
    "        auroc = self.auroc(pred,y)\n",
    "        prec, rec, thresholds = self.prc(pred,y)\n",
    "        auprc = self.auprc(pred,y)\n",
    "        if threshold is None:\n",
    "            f1=(2*prec*rec/(prec+rec)).nan_to_num(0)[:-1]\n",
    "            threshold = thresholds[torch.argmax(f1)]\n",
    "        threshold=torch.tensor(threshold)\n",
    "        self.f1.threshold=threshold\n",
    "        self.rec.threshold=threshold\n",
    "        self.mcc.threshold=threshold\n",
    "        self.stat.threshold=threshold\n",
    "        self.prec.threshold=threshold\n",
    "        f1 = self.f1(pred,y)\n",
    "        rec = self.rec(pred,y)\n",
    "        mcc = self.mcc(pred,y)\n",
    "        bacc = self.bacc(pred,y)\n",
    "        prec = self.prec(pred,y)\n",
    "        return {\n",
    "            'AUROC':auroc.cpu().item(),'AUPRC':auprc.cpu().item(),\n",
    "            'RECALL':rec.cpu().item(),'PRECISION':prec.cpu().item(),\n",
    "            'F1':f1.cpu().item(),'MCC':mcc.cpu().item(),\n",
    "            'BACC':bacc.cpu().item(),'threshold':threshold.cpu().item(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5ab63",
   "metadata": {},
   "source": [
    "contents of EGAT.py, the graph attention layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "891b7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, hidden, dropout = 0., bias=True):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim_in, hidden, bias=bias),\n",
    "            nn.LayerNorm(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, dim_out, bias=bias),\n",
    "            nn.LayerNorm(dim_out),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "class EGraphAttentionLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.alpha = alpha\n",
    "        self.concat = concat\n",
    "\n",
    "        self.W = nn.Parameter(torch.empty(size=(in_features, out_features)))\n",
    "        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
    "        self.a = nn.Parameter(torch.empty(size=(2*out_features, 1)))\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "\n",
    "    def forward(self, h, edge_attr):\n",
    "        Wh = torch.mm(h, self.W) # h.shape: (N, in_features), Wh.shape: (N, out_features)\n",
    "        e = self._prepare_attentional_mechanism_input(Wh)\n",
    "        e = e*edge_attr\n",
    "        zero_vec = -9e15*torch.ones_like(e)\n",
    "        e = torch.where(edge_attr > 0, e, zero_vec)\n",
    "        e = F.softmax(e, dim=1)\n",
    "        e = F.dropout(e, self.dropout, training=self.training)\n",
    "\n",
    "        h_prime=[]\n",
    "        for i in range(edge_attr.shape[0]):\n",
    "            h_prime.append(torch.matmul(e[i],Wh))\n",
    "\n",
    "        if self.concat:\n",
    "            h_prime = torch.cat(h_prime,dim=1)\n",
    "        else:\n",
    "            h_prime = torch.stack(h_prime,dim=0).mean(0)\n",
    "        return F.elu(h_prime),e\n",
    "\n",
    "    #compute attention coefficient\n",
    "    def _prepare_attentional_mechanism_input(self, Wh):\n",
    "        # Wh.shape (N, out_feature)\n",
    "        # self.a.shape (2 * out_feature, 1)\n",
    "        # Wh1&2.shape (N, 1)\n",
    "        # e.shape (N, N)\n",
    "        Wh1 = torch.matmul(Wh, self.a[:self.out_features, :])\n",
    "        Wh2 = torch.matmul(Wh, self.a[self.out_features:, :])\n",
    "        # broadcast add\n",
    "        e = Wh1 + Wh2.T\n",
    "        return self.leakyrelu(e)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'\n",
    "class EGAT(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, efeat, dropout=0.2, alpha=0.2):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.in_att = EGraphAttentionLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=True)\n",
    "        self.out_att = EGraphAttentionLayer(nhid*efeat, nfeat, dropout=dropout, alpha=alpha, concat=False)\n",
    "    def forward(self, x, edge_attr):\n",
    "        x_cut=x\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x, edge_attr=self.in_att(x, edge_attr)\n",
    "        x, edge_attr=self.out_att(x, edge_attr)\n",
    "        return x+x_cut, edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623aca64",
   "metadata": {},
   "source": [
    "contents of model.py, full GraphBepi model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc16161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphBepi(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feat_dim=2560, hidden_dim=256,\n",
    "        exfeat_dim=13, edge_dim=51,\n",
    "        augment_eps=0.05, dropout=0.2,\n",
    "        lr=1e-6, metrics=None, result_path=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.metrics=metrics\n",
    "        self.path=result_path\n",
    "        # loss function\n",
    "        self.loss_fn=nn.BCELoss()\n",
    "        # Hyperparameters\n",
    "        self.exfeat_dim=exfeat_dim\n",
    "        self.augment_eps = augment_eps\n",
    "        self.lr = lr\n",
    "        self.cls = 1\n",
    "        bias=False\n",
    "        self.W_v = nn.Linear(feat_dim, hidden_dim, bias=bias)\n",
    "        self.W_u1 = AE(exfeat_dim,hidden_dim,hidden_dim, bias=bias)\n",
    "        self.edge_linear=nn.Sequential(\n",
    "            nn.Linear(edge_dim,hidden_dim//4, bias=True),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        self.gat=EGAT(2*hidden_dim,hidden_dim,hidden_dim//4,dropout)\n",
    "        self.lstm1 = nn.LSTM(hidden_dim,hidden_dim//2,3,batch_first=True,bidirectional=True,dropout=dropout)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim,hidden_dim//2,3,batch_first=True,bidirectional=True,dropout=dropout)\n",
    "        # output\n",
    "        self.mlp=nn.Sequential(\n",
    "            nn.Linear(4*hidden_dim,hidden_dim,bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim,1,bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        # Initialization\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, V, edge):\n",
    "        h=[]\n",
    "        V = pad_sequence(V, batch_first=True, padding_value=0).float()\n",
    "        mask=V.sum(-1)!=0\n",
    "        if self.training and self.augment_eps > 0:\n",
    "            aug=torch.randn_like(V)\n",
    "            aug[~mask]=0\n",
    "            V = V+self.augment_eps * aug\n",
    "        mask=mask.sum(1)\n",
    "        feats,exfeats=self.W_v(V[:,:,:-self.exfeat_dim]),self.W_u1(V[:,:,-self.exfeat_dim:])\n",
    "        x_gcns=[]\n",
    "        for i in range(len(V)):\n",
    "            E=self.edge_linear(edge[i]).permute(2,0,1)\n",
    "            x1,x2=feats[i,:mask[i]],exfeats[i,:mask[i]]\n",
    "            x_gcn=torch.cat([x1,x2],-1)\n",
    "            x_gcn,E=self.gat(x_gcn,E)\n",
    "            x_gcns.append(x_gcn)\n",
    "        feats=pack_padded_sequence(feats,mask.cpu(),True,False)\n",
    "        exfeats=pack_padded_sequence(exfeats,mask.cpu(),True,False)\n",
    "        feats=pad_packed_sequence(self.lstm1(feats)[0],True)[0]\n",
    "        exfeats=pad_packed_sequence(self.lstm2(exfeats)[0],True)[0]\n",
    "        x_attns=torch.cat([feats,exfeats],-1)\n",
    "\n",
    "        x_attns=[x_attns[i,:mask[i]] for i in range(len(x_attns))]\n",
    "        h=[torch.cat([x_attn,x_gcn],-1) for x_attn,x_gcn in zip(x_attns,x_gcns)]\n",
    "        h=torch.cat(h,0)\n",
    "        return self.mlp(h)\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        feat, edge, y = batch\n",
    "        pred = self(feat, edge).squeeze(-1)\n",
    "        loss=self.loss_fn(pred,y.float())\n",
    "        self.log('train_loss', loss.cpu().item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        if self.metrics is not None:\n",
    "            result=self.metrics.calc_prc(pred.detach().clone(),y.detach().clone())\n",
    "            self.log('train_auc', result['AUROC'], on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('train_prc', result['AUPRC'], on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        feat, edge, y = batch\n",
    "        pred = self(feat, edge).squeeze(-1)\n",
    "        return pred,y\n",
    "    def validation_epoch_end(self,outputs):\n",
    "        pred,y=[],[]\n",
    "        for i,j in outputs:\n",
    "            pred.append(i)\n",
    "            y.append(j)\n",
    "        pred=torch.cat(pred,0)\n",
    "        y=torch.cat(y,0)\n",
    "        loss=self.loss_fn(pred,y.float())\n",
    "        self.log('val_loss', loss.cpu().item(), on_epoch=True, prog_bar=True, logger=True)\n",
    "        if self.metrics is not None:\n",
    "            result=self.metrics(pred.detach().clone(),y.detach().clone())\n",
    "            self.log('val_AUROC', result['AUROC'], on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('val_AUPRC', result['AUPRC'], on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('val_mcc', result['MCC'], on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('val_f1', result['F1'], on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        feat, edge, y = batch\n",
    "        pred = self(feat, edge).squeeze(-1)\n",
    "        return pred,y\n",
    "    def test_epoch_end(self,outputs):\n",
    "        pred,y=[],[]\n",
    "        for i,j in outputs:\n",
    "            pred.append(i)\n",
    "            y.append(j)\n",
    "        pred=torch.cat(pred,0)\n",
    "        y=torch.cat(y,0)\n",
    "        loss=self.loss_fn(pred,y.float())\n",
    "        if self.path:\n",
    "            if not os.path.exists(self.path):\n",
    "                os.system(f'mkdir -p {self.path}')\n",
    "            torch.save({'pred':pred.cpu(),'gt':y.cpu()},f'{self.path}/result.pkl')\n",
    "        if self.metrics is not None:\n",
    "            result=self.metrics(pred.detach().clone(),y.detach().clone())\n",
    "            self.log('test_loss', loss.cpu().item(), on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('test_AUROC', result['AUROC'], on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('test_AUPRC', result['AUPRC'], on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('test_recall', result['RECALL'], on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('test_precision', result['PRECISION'], on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('test_f1', result['F1'], on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('test_mcc', result['MCC'], on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('test_bacc', result['BACC'], on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('test_threshold', result['threshold'], on_epoch=True, prog_bar=True, logger=True)\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), betas=(0.9, 0.99), lr=self.lr, weight_decay=1e-5, eps=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad1d23",
   "metadata": {},
   "source": [
    "contents of preprocess.py, used to preprocess the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a3395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT={\n",
    "    'ALA': 'A', 'CYS': 'C', 'CCS': 'C', 'ASP': 'D', 'GLU': 'E', 'PHE': 'F',\n",
    "    'GLY': 'G', 'HIS': 'H', 'ILE': 'I', 'LYS': 'K', 'LEU': 'L',\n",
    "    'MET': 'M', 'MSE': 'M', 'ASN': 'N', 'PRO': 'P', 'GLN': 'Q', 'ARG': 'R',\n",
    "    'SER': 'S', 'THR': 'T', 'VAL': 'V', 'TRP': 'W', 'TYR': 'Y',\n",
    "}\n",
    "def pdb_split(line):\n",
    "    order=int(line[6:11].strip())\n",
    "    atom=line[11:16].strip()\n",
    "    amino=line[16:21].strip()\n",
    "    chain=line[21]\n",
    "    site=line[22:28].strip()\n",
    "    x=line[28:38].strip()\n",
    "    y=line[38:46].strip()\n",
    "    z=line[46:54].strip()\n",
    "    return order,atom,amino,chain,site,x,y,z\n",
    "def judge(line,filt_atom='CA'):\n",
    "    kind=line[:6].strip()\n",
    "    if kind not in ['HETATM','ATOM']:\n",
    "        return None\n",
    "    order,atom,amino,chain,site,x,y,z=pdb_split(line)\n",
    "    if filt_atom is not None and atom!=filt_atom:\n",
    "        return None\n",
    "    prefix=''\n",
    "    if len(amino)>3:\n",
    "        prefix=amino[0]\n",
    "        amino=amino[-3:]\n",
    "    if amino=='MSE':\n",
    "        amino='MET'\n",
    "    elif amino=='CCS' or amino[:-1]=='CS':\n",
    "        amino='CYS'\n",
    "    elif amino not in DICT.keys():\n",
    "        return None\n",
    "    return prefix+amino,chain,site,float(x),float(y),float(z)\n",
    "def process_dssp(dssp_file):\n",
    "    aa_type = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    SS_type = \"HBEGITSC\"\n",
    "    rASA_std = [115, 135, 150, 190, 210, 75, 195, 175, 200, 170,\n",
    "                185, 160, 145, 180, 225, 115, 140, 155, 255, 230]\n",
    "    with open(dssp_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    seq = \"\"\n",
    "    dssp_feature = []\n",
    "    position = []\n",
    "    p = 0\n",
    "    while lines[p].strip()[0] != \"#\":\n",
    "        p += 1\n",
    "    for i in range(p + 1, len(lines)):\n",
    "        aa = lines[i][13]\n",
    "        if aa == \"!\" or aa == \"*\":\n",
    "            continue\n",
    "        seq += aa\n",
    "        POS = lines[i][5:11].strip()\n",
    "        position.append(POS)\n",
    "        SS = lines[i][16]\n",
    "        if SS == \" \":\n",
    "            SS = \"C\"\n",
    "        SS_vec = np.zeros(8)\n",
    "        SS_vec[SS_type.find(SS)] = 1\n",
    "        PHI = float(lines[i][103:109].strip())\n",
    "        PSI = float(lines[i][109:115].strip())\n",
    "        ACC = float(lines[i][34:38].strip())\n",
    "        ASA = min(100, round(ACC / rASA_std[aa_type.find(aa)] * 100)) / 100\n",
    "        dssp_feature.append(np.concatenate((np.array([PHI, PSI, ASA]), SS_vec)))\n",
    "\n",
    "    return seq, dssp_feature,position\n",
    "def transform_dssp(dssp_feature):\n",
    "    dssp_feature = np.array(dssp_feature)\n",
    "    angle = dssp_feature[:,0:2]\n",
    "    ASA_SS = dssp_feature[:,2:]\n",
    "    radian = angle * (np.pi / 180)\n",
    "    dssp_feature = np.concatenate([np.sin(radian), np.cos(radian), ASA_SS], axis = 1)\n",
    "    return dssp_feature\n",
    "def get_dssp(ID,root):\n",
    "    if not os.path.exists(f\"{root}/dssp/\"):\n",
    "        os.mkdir(f\"{root}/dssp/\")\n",
    "    os.system(f\"./mkdssp/mkdssp -i {root}/purePDB/{ID}.pdb -o {root}/dssp/{ID}.dssp\")\n",
    "    if not os.path.exists(f\"{root}/dssp/\" + ID + \".dssp\"):\n",
    "        return None\n",
    "    dssp_seq, dssp_matrix,position = process_dssp(f\"{root}/dssp/\" + ID + \".dssp\")\n",
    "    np.save(f\"{root}/dssp/\" + ID, transform_dssp(dssp_matrix))\n",
    "    np.save(f\"{root}/dssp/\"+ID+\"_pos\",position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4df520",
   "metadata": {},
   "source": [
    "contents of graph_construction.py, used to create a representation of the structural information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd0325eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID={\n",
    "    'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4,\n",
    "    'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9,\n",
    "    'M': 10, 'N': 11, 'P': 12, 'Q': 13, 'R': 14,\n",
    "    'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19\n",
    "}\n",
    "\n",
    "def calcPROgraph(seq,coord,dseq=3,dr=10,dlong=5,k=10):\n",
    "    nodes=coord.shape[0]\n",
    "    adj=torch.zeros((nodes,nodes))\n",
    "    E=torch.zeros((nodes,nodes,21*2+2*dseq+3))\n",
    "    # C=coord.to('cuda:1')\n",
    "    dist=torch.cdist(coord,coord,2)\n",
    "    knn=dist.argsort(1)[:,1:k+1]\n",
    "    for i in range(nodes):\n",
    "        # knn=dist[i].argsort()[1:k+1]\n",
    "        for j in range(nodes):\n",
    "            not_edge=True\n",
    "            dij_seq=abs(i-j)\n",
    "            if dij_seq<dseq:\n",
    "                E[i][j][41+i-j+dseq]=1\n",
    "                not_edge=False\n",
    "            if dist[i][j]<dr and dij_seq>=dlong:\n",
    "                E[i][j][41+2*dseq]=1\n",
    "                not_edge=False\n",
    "            if j in knn[i] and dij_seq>=dlong:\n",
    "                E[i][j][42+2*dseq]=1\n",
    "                not_edge=False\n",
    "            if not_edge:\n",
    "                continue\n",
    "            adj[i][j]=1\n",
    "            E[i][j][ID.get(seq[i],20)]=1\n",
    "            E[i][j][21+ID.get(seq[j],20)]=1\n",
    "            E[i][j][43+2*dseq]=dij_seq\n",
    "            E[i][j][44+2*dseq]=dist[i][j]\n",
    "    idx=adj.nonzero().T\n",
    "    data=adj[idx[0],idx[1]]\n",
    "    adj=torch.sparse.FloatTensor(idx,data,adj.shape)\n",
    "    idx=E.nonzero().T\n",
    "    data=E[idx[0],idx[1],idx[2]]\n",
    "    E=torch.sparse.FloatTensor(idx,data,E.shape)\n",
    "    return {'adj':adj,'edge':E}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823bb00f",
   "metadata": {},
   "source": [
    "contents of utils.py, methods for loading and working with the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae61a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "amino2id={\n",
    "    '<null_0>': 0, '<pad>': 1, '<eos>': 2, '<unk>': 3,\n",
    "    'L': 4, 'A': 5, 'G': 6, 'V': 7, 'S': 8, 'E': 9, 'R': 10,\n",
    "    'T': 11, 'I': 12, 'D': 13, 'P': 14, 'K': 15, 'Q': 16,\n",
    "    'N': 17, 'F': 18, 'Y': 19, 'M': 20, 'H': 21, 'W': 22,\n",
    "    'C': 23, 'X': 24, 'B': 25, 'U': 26, 'Z': 27, 'O': 28,\n",
    "    '.': 29, '-': 30, '<null_1>': 31, '<mask>': 32, '<cath>': 33, '<af2>': 34\n",
    "}\n",
    "class chain:\n",
    "    def __init__(self):\n",
    "        self.sequence=[]\n",
    "        self.amino=[]\n",
    "        self.coord=[]\n",
    "        self.site={}\n",
    "        self.date=''\n",
    "        self.length=0\n",
    "        self.adj=None\n",
    "        self.edge=None\n",
    "        self.feat=None\n",
    "        self.dssp=None\n",
    "        self.name=''\n",
    "        self.chain_name=''\n",
    "        self.protein_name=''\n",
    "    def add(self,amino,pos,coord):\n",
    "        self.sequence.append(DICT[amino])\n",
    "        self.amino.append(amino2id[DICT[amino]])\n",
    "        self.coord.append(coord)\n",
    "        self.site[pos]=self.length\n",
    "        self.length+=1\n",
    "    def process(self):\n",
    "        self.amino=torch.LongTensor(self.amino)\n",
    "        self.coord=torch.FloatTensor(self.coord)\n",
    "        self.label=torch.zeros_like(self.amino)\n",
    "        self.sequence=''.join(self.sequence)\n",
    "    def extract(self,model,device,path):\n",
    "        if len(self)>1024 or model is None:\n",
    "            return\n",
    "        f=lambda x:model(x.to(device).unsqueeze(0),[36])['representations'][36].squeeze(0).cpu()\n",
    "        with torch.no_grad():\n",
    "            feat=f(self.amino)\n",
    "        torch.save(feat,f'{path}/feat/{self.name}_esm2.ts')\n",
    "    def load_dssp(self,path):\n",
    "        dssp=torch.Tensor(np.load(f'{path}/dssp/{self.name}.npy'))\n",
    "        pos=np.load(f'{path}/dssp/{self.name}_pos.npy')\n",
    "        self.dssp=torch.Tensor([\n",
    "            -2.4492936e-16, -2.4492936e-16,\n",
    "            1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "        ]).repeat(self.length,1)\n",
    "        self.rsa=torch.zeros(self.length)\n",
    "        for i in range(len(dssp)):\n",
    "            self.dssp[self.site[pos[i]]]=dssp[i]\n",
    "            if dssp[i][4]>0.15:\n",
    "                self.rsa[i]=1\n",
    "        self.rsa=self.rsa.bool()\n",
    "    def load_feat(self,path):\n",
    "        self.feat=torch.load(f'{path}/feat/{self.name}_esm2.ts')\n",
    "    def load_adj(self,path,self_cycle=False):\n",
    "        graph=torch.load(f'{path}/graph/{self.name}.graph')\n",
    "        self.adj=graph['adj'].to_dense()\n",
    "        self.edge=graph['edge'].to_dense()\n",
    "        if not self_cycle:\n",
    "            self.adj[range(len(self)),range(len(self))]=0\n",
    "            self.edge[range(len(self)),range(len(self))]=0\n",
    "    def get_adj(self,path,dseq=3,dr=10,dlong=5,k=10):\n",
    "        graph=calcPROgraph(self.sequence,self.coord,dseq,dr,dlong,k)\n",
    "        torch.save(graph,f'{path}/graph/{self.name}.graph')\n",
    "    def update(self,pos,amino):\n",
    "        if amino not in DICT.keys():\n",
    "            return\n",
    "        amino_id=amino2id[DICT[amino]]\n",
    "        idx=self.site.get(pos,None)\n",
    "        if idx is None:\n",
    "            for i in self.site.keys():\n",
    "                # print(i,pos)\n",
    "                if i[:len(pos)]==pos:\n",
    "                    idx=self.site.get(i)\n",
    "                    if amino_id==self.amino[idx]:\n",
    "                        self.label[idx]=1\n",
    "                        return\n",
    "        elif amino_id!=self.amino[idx]:\n",
    "            for i in self.site.keys():\n",
    "                if i[:len(pos)]==pos:\n",
    "                    idx=self.site.get(i)\n",
    "                    if amino_id==self.amino[idx]:\n",
    "                        self.label[idx]=1\n",
    "                        return\n",
    "        else:\n",
    "            self.label[idx]=1\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    def __getitem__(self,idx):\n",
    "        return self.amino[idx],self.coord[idx],self.label[idx]\n",
    "def collate_fn(batch):\n",
    "    edges = [item['edge'] for item in batch]\n",
    "    feats = [item['feat'] for item in batch]\n",
    "    labels = torch.cat([item['label'] for item in batch],0)\n",
    "    return feats,edges,labels\n",
    "\n",
    "def extract_chain(root,pid,chain,force=False):\n",
    "    if not force and os.path.exists(f'{root}/purePDB/{pid}_{chain}.pdb'):\n",
    "        return True\n",
    "    if not os.path.exists(f'{root}/PDB/{pid}.pdb'):\n",
    "        retry=5\n",
    "        pdb=None\n",
    "        with rq.get(f'https://files.rcsb.org/download/{pid}.pdb') as f:\n",
    "            if f.status_code==200:\n",
    "                pdb=f.content\n",
    "        while retry>0:\n",
    "            try:\n",
    "                with rq.get(f'https://files.rcsb.org/download/{pid}.pdb') as f:\n",
    "                    if f.status_code==200:\n",
    "                        pdb=f.content\n",
    "                        break\n",
    "            except:\n",
    "                retry-=1\n",
    "                continue\n",
    "        if pdb is None:\n",
    "            print(f'PDB file {pid} failed to download')\n",
    "            return False\n",
    "        with open(f'{root}/PDB/{pid}.pdb','wb') as f:\n",
    "            f.write(pdb)\n",
    "    lines=[]\n",
    "    with open(f'{root}/PDB/{pid}.pdb','r') as f:\n",
    "        for line in f:\n",
    "            if line[:6]=='HEADER':\n",
    "                lines.append(line)\n",
    "            if line[:6].strip()=='TER' and line[21]==chain:\n",
    "                lines.append(line)\n",
    "                break\n",
    "            feats=judge(line,None)\n",
    "            if feats is not None and feats[1]==chain:\n",
    "                lines.append(line)\n",
    "    with open(f'{root}/purePDB/{pid}_{chain}.pdb','w') as f:\n",
    "        for i in lines:\n",
    "            f.write(i)\n",
    "    return True\n",
    "def process_chain(data,root,pid,model,device):\n",
    "    get_dssp(pid,root)\n",
    "    same={}\n",
    "    with open(f'{root}/purePDB/{pid}.pdb','r') as f:\n",
    "        for line in f:\n",
    "            if line[:6]=='HEADER':\n",
    "                date=line[50:59].strip()\n",
    "                data.date=date\n",
    "                continue\n",
    "            feats=judge(line,'CA')\n",
    "            if feats is None:\n",
    "                continue\n",
    "            amino,_,site,x,y,z=feats\n",
    "            if len(amino)>3:\n",
    "                if same.get(site) is None:\n",
    "                    same[site]=amino[0]\n",
    "                if same[site]!=amino[0]:\n",
    "                    continue\n",
    "                amino=amino[-3:]\n",
    "            data.add(amino,site,[x,y,z])\n",
    "    data.process()\n",
    "    data.get_adj(root)\n",
    "    data.extract(model,device,root)\n",
    "    return data\n",
    "def initial(file,root,model=None,device='cpu',from_native_pdb=True):\n",
    "    df=pd.read_csv(f'{root}/{file}',header=0,index_col=0)\n",
    "    prefix=df.index\n",
    "    labels=df['Epitopes (resi_resn)']\n",
    "    samples=[]\n",
    "    with tqdm(prefix) as tbar:\n",
    "        for i in tbar:\n",
    "            tbar.set_postfix(protein=i)\n",
    "            if from_native_pdb:\n",
    "                state=extract_chain(root,i[:4],i[-1])\n",
    "                if not state:\n",
    "                    continue\n",
    "            data=chain()\n",
    "            p,c=i.split('_')\n",
    "            data.protein_name=p\n",
    "            data.chain_name=c\n",
    "            data.name=f\"{p}_{c}\"\n",
    "            process_chain(data,root,i,model,device)\n",
    "            label=labels.loc[i].split(', ')\n",
    "            for j in label:\n",
    "                site,amino=j.split('_')\n",
    "                data.update(site,amino)\n",
    "            samples.append(data)\n",
    "    with open(f'{root}/total.pkl','wb') as f:\n",
    "        pk.dump(samples,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba8ef7f",
   "metadata": {},
   "source": [
    "first part of the contents of dataset.py, a class for handling the protein data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac9e0cf1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class PDB(Dataset):\n",
    "    def __init__(\n",
    "        self,mode='train',fold=-1,root='.',self_cycle=False\n",
    "    ):\n",
    "        self.root=root\n",
    "        assert mode in ['train','val','test']\n",
    "        if mode in ['train','val']:\n",
    "            with open(f'{self.root}/train.pkl','rb') as f:\n",
    "                self.samples=pk.load(f)\n",
    "        else:\n",
    "            with open(f'{self.root}/test.pkl','rb') as f:\n",
    "                self.samples=pk.load(f)\n",
    "        self.data=[]\n",
    "        idx=np.load(f'{self.root}/cross-validation.npy')\n",
    "        cv=10\n",
    "        inter=len(idx)//cv\n",
    "        ex=len(idx)%cv\n",
    "        if mode=='train':\n",
    "            order=[]\n",
    "            for i in range(cv):\n",
    "                if i==fold:\n",
    "                    continue\n",
    "                order+=list(idx[i*inter:(i+1)*inter+ex*(i==cv-1)])\n",
    "        elif mode=='val':\n",
    "            order=list(idx[fold*inter:(fold+1)*inter+ex*(fold==cv-1)])\n",
    "        else:\n",
    "            order=list(range(len(self.samples)))\n",
    "        order.sort()\n",
    "        tbar=tqdm(order)\n",
    "        for i in tbar:\n",
    "            tbar.set_postfix(chain=f'{self.samples[i].name}')\n",
    "            self.samples[i].load_feat(self.root)\n",
    "            self.samples[i].load_dssp(self.root)\n",
    "            self.samples[i].load_adj(self.root,self_cycle)\n",
    "            self.data.append(self.samples[i])\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        seq=self.data[idx]\n",
    "        feat=torch.cat([seq.feat,seq.dssp],1)\n",
    "        return {\n",
    "            'feat':feat,\n",
    "            'label':seq.label,\n",
    "            'adj':seq.adj,\n",
    "            'edge':seq.edge,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68416757",
   "metadata": {},
   "source": [
    "second part of dataset.py, downloads and creates the necessary datasets (needs to be ran just once to create the needed files):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a776b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--root', type=str, default='./data/BCE_633', help='dataset path')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu.')\n",
    "args = parser.parse_args()\n",
    "root = args.root\n",
    "device='cpu' if args.gpu==-1 else f'cuda:{args.gpu}'\n",
    "'''\n",
    "root = '.'\n",
    "device = 'cuda'\n",
    "\n",
    "os.system(f'cd {root} && mkdir PDB purePDB feat dssp graph')\n",
    "model,_=esm.pretrained.esm2_t36_3B_UR50D()\n",
    "model=model.to(device)\n",
    "model.eval()\n",
    "train='DATA/total.csv'\n",
    "initial(train,root,model,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04580901",
   "metadata": {},
   "source": [
    "third part of dataset.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c46a1d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '.'\n",
    "device = 'cuda'\n",
    "with open(f'{root}/total.pkl','rb') as f:\n",
    "    dataset=pk.load(f)\n",
    "    dates={i.name:i.date for i in dataset}\n",
    "    filt_data=[]\n",
    "    for i in dataset:\n",
    "        if len(i)<1024 and i.label.sum()>0:\n",
    "            filt_data.append(i)\n",
    "    month={'JAN':1,'FEB':2,'MAR':3,'APR':4,'MAY':5,'JUN':6,'JUL':7,'AUG':8,'SEP':9,'OCT':10,'NOV':11,'DEC':12}\n",
    "    trainset,valset,testset=[],[],[]\n",
    "    D,M,Y=[],[],[]\n",
    "    test=20210401\n",
    "    dates_=[]\n",
    "    for i in filt_data:\n",
    "        d,m,y=dates[i.name].split('-')\n",
    "        d,m,y=int(d),month[m],int(y)\n",
    "        if y<23:\n",
    "            y+=2000\n",
    "        else:\n",
    "            y+=1900\n",
    "        date=y*10000+m*100+d\n",
    "        if date<test:\n",
    "            dates_.append(date)\n",
    "            trainset.append(i)\n",
    "        else:\n",
    "            testset.append(i)\n",
    "    with open(f'{root}/train.pkl','wb') as f:\n",
    "        pk.dump(trainset,f)\n",
    "    with open(f'{root}/test.pkl','wb') as f:\n",
    "        pk.dump(testset,f)\n",
    "    idx=np.array(dates_).argsort()\n",
    "    np.save(f'{root}/cross-validation.npy',idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf6e75",
   "metadata": {},
   "source": [
    "seed everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "168e3970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=2022):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04429c82",
   "metadata": {},
   "source": [
    "set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dd8691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu=0\n",
    "fold=-1\n",
    "lr=1e-6\n",
    "batch=4\n",
    "epochs=300\n",
    "root='.'\n",
    "log_name=f'BCE_633_GraphBepi'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32117cb",
   "metadata": {},
   "source": [
    "load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "013e6513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 577/577 [00:11<00:00, 49.40it/s, chain=3lh2_V]\n",
      "0it [00:00, ?it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 40.86it/s, chain=7ue9_C]\n"
     ]
    }
   ],
   "source": [
    "trainset=PDB(mode='train',fold=fold,root=root)\n",
    "valset=PDB(mode='val',fold=fold,root=root)\n",
    "testset=PDB(mode='test',root=root)\n",
    "train_loader=DataLoader(trainset, batch, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader=DataLoader(valset, batch, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader=DataLoader(testset, batch, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2160ddfb",
   "metadata": {},
   "source": [
    "create models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "776c8c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "device='cpu' if gpu==-1 else f'cuda:{gpu}'\n",
    "metrics=METRICS(device)\n",
    "es=EarlyStopping('val_AUPRC',patience=40,mode='max')\n",
    "mc=ModelCheckpoint(\n",
    "    f'./model/{log_name}/',f'model_{fold}',\n",
    "    'val_AUPRC',\n",
    "    mode='max',\n",
    "    save_weights_only=True, \n",
    ")\n",
    "logger = TensorBoardLogger(\n",
    "    './log', \n",
    "    name=f'{log_name}_{fold}'\n",
    ")\n",
    "cb=[mc,es]\n",
    "trainer = pl.Trainer( \n",
    "    max_epochs=epochs, callbacks=cb,\n",
    "    logger=logger,check_val_every_n_epoch=1,\n",
    ")\n",
    "model=GraphBepi(\n",
    "    feat_dim=2560,                     # esm2 representation dim\n",
    "    hidden_dim=256,                    # hidden representation dim\n",
    "    exfeat_dim=13,                     # dssp feature dim\n",
    "    edge_dim=51,                       # edge feature dim\n",
    "    augment_eps=0.05,                  # random noise rate\n",
    "    dropout=0.2,\n",
    "    lr=lr,                             # learning rate\n",
    "    metrics=metrics,                   # an implement to compute performance\n",
    "    result_path=f'./model/{log_name}', # path to save temporary result file of testset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c2869",
   "metadata": {},
   "source": [
    "train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710c0058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name        | Type       | Params\n",
      "-------------------------------------------\n",
      "0 | loss_fn     | BCELoss    | 0     \n",
      "1 | W_v         | Linear     | 655 K \n",
      "2 | W_u1        | AE         | 69.9 K\n",
      "3 | edge_linear | Sequential | 3.3 K \n",
      "4 | gat         | EGAT       | 8.5 M \n",
      "5 | lstm1       | LSTM       | 1.2 M \n",
      "6 | lstm2       | LSTM       | 1.2 M \n",
      "7 | mlp         | Sequential | 262 K \n",
      "-------------------------------------------\n",
      "11.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.9 M    Total params\n",
      "47.536    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  91%|██████▍| 144/158 [32:13<03:07, 13.42s/it, loss=0.384, v_num=1, train_auc_step=0.563, train_prc_step=0.132]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|████▏                                                      | 1/14 [00:00<00:09,  1.44it/s]\u001b[A\n",
      "Epoch 0:  92%|██████▍| 145/158 [32:13<02:53, 13.34s/it, loss=0.384, v_num=1, train_auc_step=0.563, train_prc_step=0.132]\u001b[A\n",
      "Validation DataLoader 0:  14%|████████▍                                                  | 2/14 [00:02<00:15,  1.26s/it]\u001b[A\n",
      "Epoch 0:  92%|██████▍| 146/158 [32:15<02:39, 13.26s/it, loss=0.384, v_num=1, train_auc_step=0.563, train_prc_step=0.132]\u001b[A\n",
      "Validation DataLoader 0:  21%|████████████▋                                              | 3/14 [00:04<00:17,  1.61s/it]\u001b[A\n",
      "Epoch 0:  93%|██████▌| 147/158 [32:17<02:24, 13.18s/it, loss=0.384, v_num=1, train_auc_step=0.563, train_prc_step=0.132]\u001b[A\n",
      "Validation DataLoader 0:  29%|████████████████▊                                          | 4/14 [00:06<00:16,  1.69s/it]\u001b[A\n",
      "Epoch 0:  94%|██████▌| 148/158 [32:19<02:11, 13.10s/it, loss=0.384, v_num=1, train_auc_step=0.563, train_prc_step=0.132]\u001b[A\n",
      "Validation DataLoader 0:  36%|█████████████████████                                      | 5/14 [00:06<00:11,  1.27s/it]\u001b[A\n",
      "Epoch 0:  94%|██████▌| 149/158 [32:19<01:57, 13.02s/it, loss=0.384, v_num=1, train_auc_step=0.563, train_prc_step=0.132]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████████████████████████▎                                 | 6/14 [00:08<00:12,  1.51s/it]\u001b[A\n",
      "Epoch 0:  95%|██████▋| 150/158 [32:21<01:43, 12.95s/it, loss=0.384, v_num=1, train_auc_step=0.563, train_prc_step=0.132]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 7/14 [00:10<00:12,  1.74s/it]\u001b[A\n",
      "Epoch 0:  96%|██████▋| 151/158 [32:24<01:30, 12.87s/it, loss=0.384, v_num=1, train_auc_step=0.563, train_prc_step=0.132]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████████████████████████████▋                         | 8/14 [00:14<00:14,  2.47s/it]\u001b[A\n",
      "Epoch 0:  96%|██████▋| 152/158 [32:28<01:16, 12.82s/it, loss=0.384, v_num=1, train_auc_step=0.563, train_prc_step=0.132]\u001b[A\n",
      "Validation DataLoader 0:  64%|█████████████████████████████████████▉                     | 9/14 [00:16<00:11,  2.21s/it]\u001b[A\n",
      "Epoch 0:  97%|██████▊| 153/158 [32:29<01:03, 12.74s/it, loss=0.384, v_num=1, train_auc_step=0.563, train_prc_step=0.132]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████████████████████████████████████▍                | 10/14 [00:21<00:11,  2.97s/it]\u001b[A\n",
      "Epoch 0:  97%|██████▊| 154/158 [32:34<00:50, 12.69s/it, loss=0.384, v_num=1, train_auc_step=0.563, train_prc_step=0.132]\u001b[A\n",
      "Validation DataLoader 0:  79%|█████████████████████████████████████████████▌            | 11/14 [00:22<00:07,  2.37s/it]\u001b[A\n",
      "Epoch 0:  98%|██████▊| 155/158 [32:35<00:37, 12.62s/it, loss=0.384, v_num=1, train_auc_step=0.563, train_prc_step=0.132]\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████████████████████████████████████████▋        | 12/14 [00:23<00:04,  2.13s/it]\u001b[A\n",
      "Epoch 0:  99%|██████▉| 156/158 [32:37<00:25, 12.55s/it, loss=0.384, v_num=1, train_auc_step=0.563, train_prc_step=0.132]\u001b[A\n",
      "Validation DataLoader 0:  93%|█████████████████████████████████████████████████████▊    | 13/14 [00:26<00:02,  2.41s/it]\u001b[A\n",
      "Epoch 0:  99%|██████▉| 157/158 [32:40<00:12, 12.48s/it, loss=0.384, v_num=1, train_auc_step=0.563, train_prc_step=0.132]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████| 14/14 [00:29<00:00,  2.33s/it]\u001b[A\n",
      "Epoch 0: 100%|█| 158/158 [32:42<00:00, 12.42s/it, loss=0.384, v_num=1, train_auc_step=0.563, train_prc_step=0.132, val_l\u001b[A\n",
      "Epoch 1:  91%|▉| 144/158 [31:41<03:04, 13.21s/it, loss=0.388, v_num=1, train_auc_step=0.639, train_prc_step=0.288, val_l\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|████▏                                                      | 1/14 [00:01<00:14,  1.14s/it]\u001b[A\n",
      "Epoch 1:  92%|▉| 145/158 [31:42<02:50, 13.12s/it, loss=0.388, v_num=1, train_auc_step=0.639, train_prc_step=0.288, val_l\u001b[A\n",
      "Validation DataLoader 0:  14%|████████▍                                                  | 2/14 [00:03<00:19,  1.62s/it]\u001b[A\n",
      "Epoch 1:  92%|▉| 146/158 [31:44<02:36, 13.05s/it, loss=0.388, v_num=1, train_auc_step=0.639, train_prc_step=0.288, val_l\u001b[A\n",
      "Validation DataLoader 0:  21%|████████████▋                                              | 3/14 [00:05<00:20,  1.83s/it]\u001b[A\n",
      "Epoch 1:  93%|▉| 147/158 [31:46<02:22, 12.97s/it, loss=0.388, v_num=1, train_auc_step=0.639, train_prc_step=0.288, val_l\u001b[A\n",
      "Validation DataLoader 0:  29%|████████████████▊                                          | 4/14 [00:07<00:18,  1.87s/it]\u001b[A\n",
      "Epoch 1:  94%|▉| 148/158 [31:48<02:08, 12.90s/it, loss=0.388, v_num=1, train_auc_step=0.639, train_prc_step=0.288, val_l\u001b[A\n",
      "Validation DataLoader 0:  36%|█████████████████████                                      | 5/14 [00:07<00:13,  1.46s/it]\u001b[A\n",
      "Epoch 1:  94%|▉| 149/158 [31:49<01:55, 12.82s/it, loss=0.388, v_num=1, train_auc_step=0.639, train_prc_step=0.288, val_l\u001b[A\n",
      "Validation DataLoader 0:  43%|█████████████████████████▎                                 | 6/14 [00:09<00:13,  1.64s/it]\u001b[A\n",
      "Epoch 1:  95%|▉| 150/158 [31:51<01:41, 12.74s/it, loss=0.388, v_num=1, train_auc_step=0.639, train_prc_step=0.288, val_l\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 7/14 [00:11<00:12,  1.78s/it]\u001b[A\n",
      "Epoch 1:  96%|▉| 151/158 [31:53<01:28, 12.67s/it, loss=0.388, v_num=1, train_auc_step=0.639, train_prc_step=0.288, val_l\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████████████████████████████▋                         | 8/14 [00:15<00:13,  2.29s/it]\u001b[A\n",
      "Epoch 1:  96%|▉| 152/158 [31:56<01:15, 12.61s/it, loss=0.388, v_num=1, train_auc_step=0.639, train_prc_step=0.288, val_l\u001b[A\n",
      "Validation DataLoader 0:  64%|█████████████████████████████████████▉                     | 9/14 [00:16<00:10,  2.01s/it]\u001b[A\n",
      "Epoch 1:  97%|▉| 153/158 [31:58<01:02, 12.54s/it, loss=0.388, v_num=1, train_auc_step=0.639, train_prc_step=0.288, val_l\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████████████████████████████████████▍                | 10/14 [00:20<00:10,  2.69s/it]\u001b[A\n",
      "Epoch 1:  97%|▉| 154/158 [32:02<00:49, 12.48s/it, loss=0.388, v_num=1, train_auc_step=0.639, train_prc_step=0.288, val_l\u001b[A\n",
      "Validation DataLoader 0:  79%|█████████████████████████████████████████████▌            | 11/14 [00:21<00:06,  2.09s/it]\u001b[A\n",
      "Epoch 1:  98%|▉| 155/158 [32:03<00:37, 12.41s/it, loss=0.388, v_num=1, train_auc_step=0.639, train_prc_step=0.288, val_l\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████████████████████████████████████████▋        | 12/14 [00:23<00:03,  1.89s/it]\u001b[A\n",
      "Epoch 1:  99%|▉| 156/158 [32:04<00:24, 12.34s/it, loss=0.388, v_num=1, train_auc_step=0.639, train_prc_step=0.288, val_l\u001b[A\n",
      "Validation DataLoader 0:  93%|█████████████████████████████████████████████████████▊    | 13/14 [00:25<00:02,  2.13s/it]\u001b[A\n",
      "Epoch 1:  99%|▉| 157/158 [32:07<00:12, 12.28s/it, loss=0.388, v_num=1, train_auc_step=0.639, train_prc_step=0.288, val_l\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████| 14/14 [00:27<00:00,  2.00s/it]\u001b[A\n",
      "Epoch 1: 100%|█| 158/158 [32:09<00:00, 12.21s/it, loss=0.388, v_num=1, train_auc_step=0.639, train_prc_step=0.288, val_l\u001b[A\n",
      "Epoch 2:  91%|▉| 144/158 [32:16<03:08, 13.45s/it, loss=0.363, v_num=1, train_auc_step=0.674, train_prc_step=0.233, val_l\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|████▏                                                      | 1/14 [00:01<00:13,  1.06s/it]\u001b[A\n",
      "Epoch 2:  92%|▉| 145/158 [32:17<02:53, 13.36s/it, loss=0.363, v_num=1, train_auc_step=0.674, train_prc_step=0.233, val_l\u001b[A\n",
      "Validation DataLoader 0:  14%|████████▍                                                  | 2/14 [00:03<00:22,  1.85s/it]\u001b[A\n",
      "Epoch 2:  92%|▉| 146/158 [32:19<02:39, 13.29s/it, loss=0.363, v_num=1, train_auc_step=0.674, train_prc_step=0.233, val_l\u001b[A\n",
      "Validation DataLoader 0:  21%|████████████▋                                              | 3/14 [00:05<00:23,  2.12s/it]\u001b[A\n",
      "Epoch 2:  93%|▉| 147/158 [32:22<02:25, 13.21s/it, loss=0.363, v_num=1, train_auc_step=0.674, train_prc_step=0.233, val_l\u001b[A\n",
      "Validation DataLoader 0:  29%|████████████████▊                                          | 4/14 [00:08<00:22,  2.26s/it]\u001b[A\n",
      "Epoch 2:  94%|▉| 148/158 [32:24<02:11, 13.14s/it, loss=0.363, v_num=1, train_auc_step=0.674, train_prc_step=0.233, val_l\u001b[A\n",
      "Validation DataLoader 0:  36%|█████████████████████                                      | 5/14 [00:09<00:16,  1.79s/it]\u001b[A\n",
      "Epoch 2:  94%|▉| 149/158 [32:25<01:57, 13.06s/it, loss=0.363, v_num=1, train_auc_step=0.674, train_prc_step=0.233, val_l\u001b[A\n",
      "Validation DataLoader 0:  43%|█████████████████████████▎                                 | 6/14 [00:11<00:15,  1.91s/it]\u001b[A\n",
      "Epoch 2:  95%|▉| 150/158 [32:27<01:43, 12.99s/it, loss=0.363, v_num=1, train_auc_step=0.674, train_prc_step=0.233, val_l\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 7/14 [00:13<00:14,  2.02s/it]\u001b[A\n",
      "Epoch 2:  96%|▉| 151/158 [32:30<01:30, 12.91s/it, loss=0.363, v_num=1, train_auc_step=0.674, train_prc_step=0.233, val_l\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████████████████████████████▋                         | 8/14 [00:17<00:15,  2.62s/it]\u001b[A\n",
      "Epoch 2:  96%|▉| 152/158 [32:33<01:17, 12.86s/it, loss=0.363, v_num=1, train_auc_step=0.674, train_prc_step=0.233, val_l\u001b[A\n",
      "Validation DataLoader 0:  64%|█████████████████████████████████████▉                     | 9/14 [00:18<00:10,  2.19s/it]\u001b[A\n",
      "Epoch 2:  97%|▉| 153/158 [32:35<01:03, 12.78s/it, loss=0.363, v_num=1, train_auc_step=0.674, train_prc_step=0.233, val_l\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████████████████████████████████████▍                | 10/14 [00:22<00:10,  2.74s/it]\u001b[A\n",
      "Epoch 2:  97%|▉| 154/158 [32:39<00:50, 12.72s/it, loss=0.363, v_num=1, train_auc_step=0.674, train_prc_step=0.233, val_l\u001b[A\n",
      "Validation DataLoader 0:  79%|█████████████████████████████████████████████▌            | 11/14 [00:23<00:06,  2.23s/it]\u001b[A\n",
      "Epoch 2:  98%|▉| 155/158 [32:40<00:37, 12.65s/it, loss=0.363, v_num=1, train_auc_step=0.674, train_prc_step=0.233, val_l\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████████████████████████████████████████▋        | 12/14 [00:25<00:03,  1.90s/it]\u001b[A\n",
      "Epoch 2:  99%|▉| 156/158 [32:41<00:25, 12.57s/it, loss=0.363, v_num=1, train_auc_step=0.674, train_prc_step=0.233, val_l\u001b[A\n",
      "Validation DataLoader 0:  93%|█████████████████████████████████████████████████████▊    | 13/14 [00:27<00:02,  2.01s/it]\u001b[A\n",
      "Epoch 2:  99%|▉| 157/158 [32:43<00:12, 12.51s/it, loss=0.363, v_num=1, train_auc_step=0.674, train_prc_step=0.233, val_l\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████| 14/14 [00:28<00:00,  1.88s/it]\u001b[A\n",
      "Epoch 2: 100%|█| 158/158 [32:45<00:00, 12.44s/it, loss=0.363, v_num=1, train_auc_step=0.674, train_prc_step=0.233, val_l\u001b[A\n",
      "Epoch 3:  91%|▉| 144/158 [32:22<03:08, 13.49s/it, loss=0.358, v_num=1, train_auc_step=0.687, train_prc_step=0.309, val_l\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|████▏                                                      | 1/14 [00:00<00:11,  1.12it/s]\u001b[A\n",
      "Epoch 3:  92%|▉| 145/158 [32:23<02:54, 13.40s/it, loss=0.358, v_num=1, train_auc_step=0.687, train_prc_step=0.309, val_l\u001b[A\n",
      "Validation DataLoader 0:  14%|████████▍                                                  | 2/14 [00:03<00:19,  1.64s/it]\u001b[A\n",
      "Epoch 3:  92%|▉| 146/158 [32:25<02:39, 13.33s/it, loss=0.358, v_num=1, train_auc_step=0.687, train_prc_step=0.309, val_l\u001b[A\n",
      "Validation DataLoader 0:  21%|████████████▋                                              | 3/14 [00:05<00:20,  1.89s/it]\u001b[A\n",
      "Epoch 3:  93%|▉| 147/158 [32:28<02:25, 13.25s/it, loss=0.358, v_num=1, train_auc_step=0.687, train_prc_step=0.309, val_l\u001b[A\n",
      "Validation DataLoader 0:  29%|████████████████▊                                          | 4/14 [00:07<00:21,  2.10s/it]\u001b[A\n",
      "Epoch 3:  94%|▉| 148/158 [32:30<02:11, 13.18s/it, loss=0.358, v_num=1, train_auc_step=0.687, train_prc_step=0.309, val_l\u001b[A\n",
      "Validation DataLoader 0:  36%|█████████████████████                                      | 5/14 [00:08<00:14,  1.65s/it]\u001b[A\n",
      "Epoch 3:  94%|▉| 149/158 [32:31<01:57, 13.10s/it, loss=0.358, v_num=1, train_auc_step=0.687, train_prc_step=0.309, val_l\u001b[A\n",
      "Validation DataLoader 0:  43%|█████████████████████████▎                                 | 6/14 [00:10<00:14,  1.81s/it]\u001b[A\n",
      "Epoch 3:  95%|▉| 150/158 [32:33<01:44, 13.02s/it, loss=0.358, v_num=1, train_auc_step=0.687, train_prc_step=0.309, val_l\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 7/14 [00:12<00:13,  1.95s/it]\u001b[A\n",
      "Epoch 3:  96%|▉| 151/158 [32:35<01:30, 12.95s/it, loss=0.358, v_num=1, train_auc_step=0.687, train_prc_step=0.309, val_l\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████████████████████████████▋                         | 8/14 [00:16<00:14,  2.49s/it]\u001b[A\n",
      "Epoch 3:  96%|▉| 152/158 [32:39<01:17, 12.89s/it, loss=0.358, v_num=1, train_auc_step=0.687, train_prc_step=0.309, val_l\u001b[A\n",
      "Validation DataLoader 0:  64%|█████████████████████████████████████▉                     | 9/14 [00:17<00:10,  2.07s/it]\u001b[A\n",
      "Epoch 3:  97%|▉| 153/158 [32:40<01:04, 12.81s/it, loss=0.358, v_num=1, train_auc_step=0.687, train_prc_step=0.309, val_l\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████████████████████████████████████▍                | 10/14 [00:22<00:11,  2.84s/it]\u001b[A\n",
      "Epoch 3:  97%|▉| 154/158 [32:44<00:51, 12.76s/it, loss=0.358, v_num=1, train_auc_step=0.687, train_prc_step=0.309, val_l\u001b[A\n",
      "Validation DataLoader 0:  79%|█████████████████████████████████████████████▌            | 11/14 [00:23<00:06,  2.30s/it]\u001b[A\n",
      "Epoch 3:  98%|▉| 155/158 [32:46<00:38, 12.68s/it, loss=0.358, v_num=1, train_auc_step=0.687, train_prc_step=0.309, val_l\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████████████████████████████████████████▋        | 12/14 [00:24<00:04,  2.01s/it]\u001b[A\n",
      "Epoch 3:  99%|▉| 156/158 [32:47<00:25, 12.61s/it, loss=0.358, v_num=1, train_auc_step=0.687, train_prc_step=0.309, val_l\u001b[A\n",
      "Validation DataLoader 0:  93%|█████████████████████████████████████████████████████▊    | 13/14 [00:27<00:02,  2.35s/it]\u001b[A\n",
      "Epoch 3:  99%|▉| 157/158 [32:50<00:12, 12.55s/it, loss=0.358, v_num=1, train_auc_step=0.687, train_prc_step=0.309, val_l\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████| 14/14 [00:29<00:00,  2.22s/it]\u001b[A\n",
      "Epoch 3: 100%|█| 158/158 [32:52<00:00, 12.48s/it, loss=0.358, v_num=1, train_auc_step=0.687, train_prc_step=0.309, val_l\u001b[A\n",
      "Epoch 4:  91%|▉| 144/158 [31:37<03:04, 13.18s/it, loss=0.374, v_num=1, train_auc_step=0.737, train_prc_step=0.154, val_l\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|████▏                                                      | 1/14 [00:00<00:11,  1.17it/s]\u001b[A\n",
      "Epoch 4:  92%|▉| 145/158 [31:38<02:50, 13.09s/it, loss=0.374, v_num=1, train_auc_step=0.737, train_prc_step=0.154, val_l\u001b[A\n",
      "Validation DataLoader 0:  14%|████████▍                                                  | 2/14 [00:02<00:19,  1.58s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  92%|▉| 146/158 [31:40<02:36, 13.02s/it, loss=0.374, v_num=1, train_auc_step=0.737, train_prc_step=0.154, val_l\u001b[A\n",
      "Validation DataLoader 0:  21%|████████████▋                                              | 3/14 [00:05<00:21,  1.99s/it]\u001b[A\n",
      "Epoch 4:  93%|▉| 147/158 [31:42<02:22, 12.94s/it, loss=0.374, v_num=1, train_auc_step=0.737, train_prc_step=0.154, val_l\u001b[A\n",
      "Validation DataLoader 0:  29%|████████████████▊                                          | 4/14 [00:07<00:19,  1.99s/it]\u001b[A\n",
      "Epoch 4:  94%|▉| 148/158 [31:44<02:08, 12.87s/it, loss=0.374, v_num=1, train_auc_step=0.737, train_prc_step=0.154, val_l\u001b[A\n",
      "Validation DataLoader 0:  36%|█████████████████████                                      | 5/14 [00:08<00:14,  1.57s/it]\u001b[A\n",
      "Epoch 4:  94%|▉| 149/158 [31:45<01:55, 12.79s/it, loss=0.374, v_num=1, train_auc_step=0.737, train_prc_step=0.154, val_l\u001b[A\n",
      "Validation DataLoader 0:  43%|█████████████████████████▎                                 | 6/14 [00:10<00:13,  1.68s/it]\u001b[A\n",
      "Epoch 4:  95%|▉| 150/158 [31:47<01:41, 12.72s/it, loss=0.374, v_num=1, train_auc_step=0.737, train_prc_step=0.154, val_l\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 7/14 [00:12<00:13,  1.86s/it]\u001b[A\n",
      "Epoch 4:  96%|▉| 151/158 [31:49<01:28, 12.65s/it, loss=0.374, v_num=1, train_auc_step=0.737, train_prc_step=0.154, val_l\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████████████████████████████▋                         | 8/14 [00:15<00:14,  2.42s/it]\u001b[A\n",
      "Epoch 4:  96%|▉| 152/158 [31:53<01:15, 12.59s/it, loss=0.374, v_num=1, train_auc_step=0.737, train_prc_step=0.154, val_l\u001b[A\n",
      "Validation DataLoader 0:  64%|█████████████████████████████████████▉                     | 9/14 [00:17<00:10,  2.14s/it]\u001b[A\n",
      "Epoch 4:  97%|▉| 153/158 [31:54<01:02, 12.52s/it, loss=0.374, v_num=1, train_auc_step=0.737, train_prc_step=0.154, val_l\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████████████████████████████████████▍                | 10/14 [00:21<00:11,  2.81s/it]\u001b[A\n",
      "Epoch 4:  97%|▉| 154/158 [31:59<00:49, 12.46s/it, loss=0.374, v_num=1, train_auc_step=0.737, train_prc_step=0.154, val_l\u001b[A\n",
      "Validation DataLoader 0:  79%|█████████████████████████████████████████████▌            | 11/14 [00:22<00:06,  2.24s/it]\u001b[A\n",
      "Epoch 4:  98%|▉| 155/158 [32:00<00:37, 12.39s/it, loss=0.374, v_num=1, train_auc_step=0.737, train_prc_step=0.154, val_l\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████████████████████████████████████████▋        | 12/14 [00:24<00:04,  2.03s/it]\u001b[A\n",
      "Epoch 4:  99%|▉| 156/158 [32:01<00:24, 12.32s/it, loss=0.374, v_num=1, train_auc_step=0.737, train_prc_step=0.154, val_l\u001b[A\n",
      "Validation DataLoader 0:  93%|█████████████████████████████████████████████████████▊    | 13/14 [00:27<00:02,  2.37s/it]\u001b[A\n",
      "Epoch 4:  99%|▉| 157/158 [32:04<00:12, 12.26s/it, loss=0.374, v_num=1, train_auc_step=0.737, train_prc_step=0.154, val_l\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████| 14/14 [00:29<00:00,  2.30s/it]\u001b[A\n",
      "Epoch 4: 100%|█| 158/158 [32:07<00:00, 12.20s/it, loss=0.374, v_num=1, train_auc_step=0.737, train_prc_step=0.154, val_l\u001b[A\n",
      "Epoch 5:  91%|▉| 144/158 [33:25<03:14, 13.93s/it, loss=0.365, v_num=1, train_auc_step=0.620, train_prc_step=0.199, val_l\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|████▏                                                      | 1/14 [00:00<00:10,  1.28it/s]\u001b[A\n",
      "Epoch 5:  92%|▉| 145/158 [33:26<02:59, 13.83s/it, loss=0.365, v_num=1, train_auc_step=0.620, train_prc_step=0.199, val_l\u001b[A\n",
      "Validation DataLoader 0:  14%|████████▍                                                  | 2/14 [00:03<00:22,  1.84s/it]\u001b[A\n",
      "Epoch 5:  92%|▉| 146/158 [33:28<02:45, 13.76s/it, loss=0.365, v_num=1, train_auc_step=0.620, train_prc_step=0.199, val_l\u001b[A\n",
      "Validation DataLoader 0:  21%|████████████▋                                              | 3/14 [00:05<00:22,  2.07s/it]\u001b[A\n",
      "Epoch 5:  93%|▉| 147/158 [33:30<02:30, 13.68s/it, loss=0.365, v_num=1, train_auc_step=0.620, train_prc_step=0.199, val_l\u001b[A\n",
      "Validation DataLoader 0:  29%|████████████████▊                                          | 4/14 [00:08<00:23,  2.38s/it]\u001b[A\n",
      "Epoch 5:  94%|▉| 148/158 [33:33<02:16, 13.61s/it, loss=0.365, v_num=1, train_auc_step=0.620, train_prc_step=0.199, val_l\u001b[A\n",
      "Validation DataLoader 0:  36%|█████████████████████                                      | 5/14 [00:09<00:16,  1.82s/it]\u001b[A\n",
      "Epoch 5:  94%|▉| 149/158 [33:34<02:01, 13.52s/it, loss=0.365, v_num=1, train_auc_step=0.620, train_prc_step=0.199, val_l\u001b[A\n",
      "Validation DataLoader 0:  43%|█████████████████████████▎                                 | 6/14 [00:11<00:15,  1.98s/it]\u001b[A\n",
      "Epoch 5:  95%|▉| 150/158 [33:36<01:47, 13.45s/it, loss=0.365, v_num=1, train_auc_step=0.620, train_prc_step=0.199, val_l\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 7/14 [00:13<00:14,  2.06s/it]\u001b[A\n",
      "Epoch 5:  96%|▉| 151/158 [33:39<01:33, 13.37s/it, loss=0.365, v_num=1, train_auc_step=0.620, train_prc_step=0.199, val_l\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████████████████████████████▋                         | 8/14 [00:17<00:16,  2.69s/it]\u001b[A\n",
      "Epoch 5:  96%|▉| 152/158 [33:43<01:19, 13.31s/it, loss=0.365, v_num=1, train_auc_step=0.620, train_prc_step=0.199, val_l\u001b[A\n",
      "Validation DataLoader 0:  64%|█████████████████████████████████████▉                     | 9/14 [00:19<00:11,  2.26s/it]\u001b[A\n",
      "Epoch 5:  97%|▉| 153/158 [33:44<01:06, 13.23s/it, loss=0.365, v_num=1, train_auc_step=0.620, train_prc_step=0.199, val_l\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████████████████████████████████████▍                | 10/14 [00:23<00:11,  2.81s/it]\u001b[A\n",
      "Epoch 5:  97%|▉| 154/158 [33:48<00:52, 13.17s/it, loss=0.365, v_num=1, train_auc_step=0.620, train_prc_step=0.199, val_l\u001b[A\n",
      "Validation DataLoader 0:  79%|█████████████████████████████████████████████▌            | 11/14 [00:24<00:06,  2.27s/it]\u001b[A\n",
      "Epoch 5:  98%|▉| 155/158 [33:49<00:39, 13.09s/it, loss=0.365, v_num=1, train_auc_step=0.620, train_prc_step=0.199, val_l\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████████████████████████████████████████▋        | 12/14 [00:25<00:03,  1.97s/it]\u001b[A\n",
      "Epoch 5:  99%|▉| 156/158 [33:50<00:26, 13.02s/it, loss=0.365, v_num=1, train_auc_step=0.620, train_prc_step=0.199, val_l\u001b[A\n",
      "Validation DataLoader 0:  93%|█████████████████████████████████████████████████████▊    | 13/14 [00:28<00:02,  2.25s/it]\u001b[A\n",
      "Epoch 5:  99%|▉| 157/158 [33:53<00:12, 12.95s/it, loss=0.365, v_num=1, train_auc_step=0.620, train_prc_step=0.199, val_l\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████| 14/14 [00:30<00:00,  2.23s/it]\u001b[A\n",
      "Epoch 5: 100%|█| 158/158 [33:56<00:00, 12.89s/it, loss=0.365, v_num=1, train_auc_step=0.620, train_prc_step=0.199, val_l\u001b[A\n",
      "Epoch 6:  91%|▉| 144/158 [33:46<03:16, 14.07s/it, loss=0.355, v_num=1, train_auc_step=0.689, train_prc_step=0.204, val_l\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|████▏                                                      | 1/14 [00:01<00:13,  1.04s/it]\u001b[A\n",
      "Epoch 6:  92%|▉| 145/158 [33:47<03:01, 13.98s/it, loss=0.355, v_num=1, train_auc_step=0.689, train_prc_step=0.204, val_l\u001b[A\n",
      "Validation DataLoader 0:  14%|████████▍                                                  | 2/14 [00:03<00:23,  1.92s/it]\u001b[A\n",
      "Epoch 6:  92%|▉| 146/158 [33:49<02:46, 13.90s/it, loss=0.355, v_num=1, train_auc_step=0.689, train_prc_step=0.204, val_l\u001b[A\n",
      "Validation DataLoader 0:  21%|████████████▋                                              | 3/14 [00:05<00:23,  2.09s/it]\u001b[A\n",
      "Epoch 6:  93%|▉| 147/158 [33:52<02:32, 13.82s/it, loss=0.355, v_num=1, train_auc_step=0.689, train_prc_step=0.204, val_l\u001b[A\n",
      "Validation DataLoader 0:  29%|████████████████▊                                          | 4/14 [00:08<00:21,  2.18s/it]\u001b[A\n",
      "Epoch 6:  94%|▉| 148/158 [33:54<02:17, 13.75s/it, loss=0.355, v_num=1, train_auc_step=0.689, train_prc_step=0.204, val_l\u001b[A\n",
      "Validation DataLoader 0:  36%|█████████████████████                                      | 5/14 [00:08<00:14,  1.65s/it]\u001b[A\n",
      "Epoch 6:  94%|▉| 149/158 [33:55<02:02, 13.66s/it, loss=0.355, v_num=1, train_auc_step=0.689, train_prc_step=0.204, val_l\u001b[A\n",
      "Validation DataLoader 0:  43%|█████████████████████████▎                                 | 6/14 [00:11<00:14,  1.81s/it]\u001b[A\n",
      "Epoch 6:  95%|▉| 150/158 [33:57<01:48, 13.58s/it, loss=0.355, v_num=1, train_auc_step=0.689, train_prc_step=0.204, val_l\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 7/14 [00:12<00:12,  1.85s/it]\u001b[A\n",
      "Epoch 6:  96%|▉| 151/158 [33:59<01:34, 13.50s/it, loss=0.355, v_num=1, train_auc_step=0.689, train_prc_step=0.204, val_l\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████████████████████████████▋                         | 8/14 [00:16<00:14,  2.44s/it]\u001b[A\n",
      "Epoch 6:  96%|▉| 152/158 [34:02<01:20, 13.44s/it, loss=0.355, v_num=1, train_auc_step=0.689, train_prc_step=0.204, val_l\u001b[A\n",
      "Validation DataLoader 0:  64%|█████████████████████████████████████▉                     | 9/14 [00:18<00:10,  2.13s/it]\u001b[A\n",
      "Epoch 6:  97%|▉| 153/158 [34:04<01:06, 13.36s/it, loss=0.355, v_num=1, train_auc_step=0.689, train_prc_step=0.204, val_l\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████████████████████████████████████▍                | 10/14 [00:22<00:11,  2.78s/it]\u001b[A\n",
      "Epoch 6:  97%|▉| 154/158 [34:08<00:53, 13.30s/it, loss=0.355, v_num=1, train_auc_step=0.689, train_prc_step=0.204, val_l\u001b[A\n",
      "Validation DataLoader 0:  79%|█████████████████████████████████████████████▌            | 11/14 [00:23<00:06,  2.21s/it]\u001b[A\n",
      "Epoch 6:  98%|▉| 155/158 [34:09<00:39, 13.22s/it, loss=0.355, v_num=1, train_auc_step=0.689, train_prc_step=0.204, val_l\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████████████████████████████████████████▋        | 12/14 [00:24<00:04,  2.00s/it]\u001b[A\n",
      "Epoch 6:  99%|▉| 156/158 [34:11<00:26, 13.15s/it, loss=0.355, v_num=1, train_auc_step=0.689, train_prc_step=0.204, val_l\u001b[A\n",
      "Validation DataLoader 0:  93%|█████████████████████████████████████████████████████▊    | 13/14 [00:27<00:02,  2.29s/it]\u001b[A\n",
      "Epoch 6:  99%|▉| 157/158 [34:14<00:13, 13.08s/it, loss=0.355, v_num=1, train_auc_step=0.689, train_prc_step=0.204, val_l\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████| 14/14 [00:29<00:00,  2.16s/it]\u001b[A\n",
      "Epoch 6: 100%|█| 158/158 [34:15<00:00, 13.01s/it, loss=0.355, v_num=1, train_auc_step=0.689, train_prc_step=0.204, val_l\u001b[A\n",
      "Epoch 7:  91%|▉| 144/158 [32:54<03:11, 13.71s/it, loss=0.373, v_num=1, train_auc_step=0.654, train_prc_step=0.227, val_l\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|████▏                                                      | 1/14 [00:01<00:14,  1.09s/it]\u001b[A\n",
      "Epoch 7:  92%|▉| 145/158 [32:55<02:57, 13.62s/it, loss=0.373, v_num=1, train_auc_step=0.654, train_prc_step=0.227, val_l\u001b[A\n",
      "Validation DataLoader 0:  14%|████████▍                                                  | 2/14 [00:03<00:21,  1.83s/it]\u001b[A\n",
      "Epoch 7:  92%|▉| 146/158 [32:57<02:42, 13.54s/it, loss=0.373, v_num=1, train_auc_step=0.654, train_prc_step=0.227, val_l\u001b[A\n",
      "Validation DataLoader 0:  21%|████████████▋                                              | 3/14 [00:05<00:23,  2.14s/it]\u001b[A\n",
      "Epoch 7:  93%|▉| 147/158 [33:00<02:28, 13.47s/it, loss=0.373, v_num=1, train_auc_step=0.654, train_prc_step=0.227, val_l\u001b[A\n",
      "Validation DataLoader 0:  29%|████████████████▊                                          | 4/14 [00:08<00:21,  2.18s/it]\u001b[A\n",
      "Epoch 7:  94%|▉| 148/158 [33:02<02:13, 13.39s/it, loss=0.373, v_num=1, train_auc_step=0.654, train_prc_step=0.227, val_l\u001b[A\n",
      "Validation DataLoader 0:  36%|█████████████████████                                      | 5/14 [00:09<00:15,  1.74s/it]\u001b[A\n",
      "Epoch 7:  94%|▉| 149/158 [33:03<01:59, 13.31s/it, loss=0.373, v_num=1, train_auc_step=0.654, train_prc_step=0.227, val_l\u001b[A\n",
      "Validation DataLoader 0:  43%|█████████████████████████▎                                 | 6/14 [00:11<00:14,  1.86s/it]\u001b[A\n",
      "Epoch 7:  95%|▉| 150/158 [33:05<01:45, 13.24s/it, loss=0.373, v_num=1, train_auc_step=0.654, train_prc_step=0.227, val_l\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 7/14 [00:13<00:13,  1.90s/it]\u001b[A\n",
      "Epoch 7:  96%|▉| 151/158 [33:07<01:32, 13.16s/it, loss=0.373, v_num=1, train_auc_step=0.654, train_prc_step=0.227, val_l\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████████████████████████████▋                         | 8/14 [00:16<00:14,  2.44s/it]\u001b[A\n",
      "Epoch 7:  96%|▉| 152/158 [33:10<01:18, 13.10s/it, loss=0.373, v_num=1, train_auc_step=0.654, train_prc_step=0.227, val_l\u001b[A\n",
      "Validation DataLoader 0:  64%|█████████████████████████████████████▉                     | 9/14 [00:18<00:10,  2.14s/it]\u001b[A\n",
      "Epoch 7:  97%|▉| 153/158 [33:12<01:05, 13.02s/it, loss=0.373, v_num=1, train_auc_step=0.654, train_prc_step=0.227, val_l\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████████████████████████████████████▍                | 10/14 [00:22<00:11,  2.80s/it]\u001b[A\n",
      "Epoch 7:  97%|▉| 154/158 [33:16<00:51, 12.97s/it, loss=0.373, v_num=1, train_auc_step=0.654, train_prc_step=0.227, val_l\u001b[A\n",
      "Validation DataLoader 0:  79%|█████████████████████████████████████████████▌            | 11/14 [00:23<00:06,  2.20s/it]\u001b[A\n",
      "Epoch 7:  98%|▉| 155/158 [33:17<00:38, 12.89s/it, loss=0.373, v_num=1, train_auc_step=0.654, train_prc_step=0.227, val_l\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████████████████████████████████████████▋        | 12/14 [00:24<00:03,  1.97s/it]\u001b[A\n",
      "Epoch 7:  99%|▉| 156/158 [33:18<00:25, 12.81s/it, loss=0.373, v_num=1, train_auc_step=0.654, train_prc_step=0.227, val_l\u001b[A\n",
      "Validation DataLoader 0:  93%|█████████████████████████████████████████████████████▊    | 13/14 [00:27<00:02,  2.26s/it]\u001b[A\n",
      "Epoch 7:  99%|▉| 157/158 [33:21<00:12, 12.75s/it, loss=0.373, v_num=1, train_auc_step=0.654, train_prc_step=0.227, val_l\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████| 14/14 [00:29<00:00,  2.21s/it]\u001b[A\n",
      "Epoch 7: 100%|█| 158/158 [33:24<00:00, 12.68s/it, loss=0.373, v_num=1, train_auc_step=0.654, train_prc_step=0.227, val_l\u001b[A\n",
      "Epoch 8:  91%|▉| 144/158 [32:44<03:11, 13.64s/it, loss=0.345, v_num=1, train_auc_step=0.622, train_prc_step=0.224, val_l\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|████▏                                                      | 1/14 [00:01<00:14,  1.09s/it]\u001b[A\n",
      "Epoch 8:  92%|▉| 145/158 [32:45<02:56, 13.56s/it, loss=0.345, v_num=1, train_auc_step=0.622, train_prc_step=0.224, val_l\u001b[A\n",
      "Validation DataLoader 0:  14%|████████▍                                                  | 2/14 [00:03<00:22,  1.85s/it]\u001b[A\n",
      "Epoch 8:  92%|▉| 146/158 [32:48<02:41, 13.48s/it, loss=0.345, v_num=1, train_auc_step=0.622, train_prc_step=0.224, val_l\u001b[A\n",
      "Validation DataLoader 0:  21%|████████████▋                                              | 3/14 [00:05<00:23,  2.10s/it]\u001b[A\n",
      "Epoch 8:  93%|▉| 147/158 [32:50<02:27, 13.41s/it, loss=0.345, v_num=1, train_auc_step=0.622, train_prc_step=0.224, val_l\u001b[A\n",
      "Validation DataLoader 0:  29%|████████████████▊                                          | 4/14 [00:08<00:23,  2.31s/it]\u001b[A\n",
      "Epoch 8:  94%|▉| 148/158 [32:53<02:13, 13.33s/it, loss=0.345, v_num=1, train_auc_step=0.622, train_prc_step=0.224, val_l\u001b[A\n",
      "Validation DataLoader 0:  36%|█████████████████████                                      | 5/14 [00:09<00:15,  1.77s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  94%|▉| 149/158 [32:54<01:59, 13.25s/it, loss=0.345, v_num=1, train_auc_step=0.622, train_prc_step=0.224, val_l\u001b[A\n",
      "Validation DataLoader 0:  43%|█████████████████████████▎                                 | 6/14 [00:11<00:14,  1.85s/it]\u001b[A\n",
      "Epoch 8:  95%|▉| 150/158 [32:56<01:45, 13.17s/it, loss=0.345, v_num=1, train_auc_step=0.622, train_prc_step=0.224, val_l\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 7/14 [00:13<00:12,  1.84s/it]\u001b[A\n",
      "Epoch 8:  96%|▉| 151/158 [32:57<01:31, 13.10s/it, loss=0.345, v_num=1, train_auc_step=0.622, train_prc_step=0.224, val_l\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████████████████████████████▋                         | 8/14 [00:16<00:14,  2.39s/it]\u001b[A\n",
      "Epoch 8:  96%|▉| 152/158 [33:01<01:18, 13.04s/it, loss=0.345, v_num=1, train_auc_step=0.622, train_prc_step=0.224, val_l\u001b[A\n",
      "Validation DataLoader 0:  64%|█████████████████████████████████████▉                     | 9/14 [00:17<00:10,  2.03s/it]\u001b[A\n",
      "Epoch 8:  97%|▉| 153/158 [33:02<01:04, 12.96s/it, loss=0.345, v_num=1, train_auc_step=0.622, train_prc_step=0.224, val_l\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████████████████████████████████████▍                | 10/14 [00:22<00:10,  2.73s/it]\u001b[A\n",
      "Epoch 8:  97%|▉| 154/158 [33:07<00:51, 12.90s/it, loss=0.345, v_num=1, train_auc_step=0.622, train_prc_step=0.224, val_l\u001b[A\n",
      "Validation DataLoader 0:  79%|█████████████████████████████████████████████▌            | 11/14 [00:23<00:06,  2.19s/it]\u001b[A\n",
      "Epoch 8:  98%|▉| 155/158 [33:07<00:38, 12.83s/it, loss=0.345, v_num=1, train_auc_step=0.622, train_prc_step=0.224, val_l\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████████████████████████████████████████▋        | 12/14 [00:24<00:03,  1.97s/it]\u001b[A\n",
      "Epoch 8:  99%|▉| 156/158 [33:09<00:25, 12.75s/it, loss=0.345, v_num=1, train_auc_step=0.622, train_prc_step=0.224, val_l\u001b[A\n",
      "Validation DataLoader 0:  93%|█████████████████████████████████████████████████████▊    | 13/14 [00:27<00:02,  2.30s/it]\u001b[A\n",
      "Epoch 8:  99%|▉| 157/158 [33:12<00:12, 12.69s/it, loss=0.345, v_num=1, train_auc_step=0.622, train_prc_step=0.224, val_l\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████| 14/14 [00:29<00:00,  2.13s/it]\u001b[A\n",
      "Epoch 8: 100%|█| 158/158 [33:14<00:00, 12.62s/it, loss=0.345, v_num=1, train_auc_step=0.622, train_prc_step=0.224, val_l\u001b[A\n",
      "Epoch 9:  78%|▊| 124/158 [28:14<07:44, 13.67s/it, loss=0.341, v_num=1, train_auc_step=0.656, train_prc_step=0.196, val_l\u001b[A"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c489afd8",
   "metadata": {},
   "source": [
    "TBC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
